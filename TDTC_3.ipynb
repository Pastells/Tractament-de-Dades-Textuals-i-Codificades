{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce84252e-7504-454e-a623-372e29b9a0e0",
   "metadata": {
    "id": "H_q6BC-xUO_j"
   },
   "source": [
    "# 3. Part-of-Speech (PoS) Tagging\n",
    "\n",
    "Tractament de Dades Textuals i Codificades — Eixample Clínic, 2026\n",
    "\n",
    "Pol Pastells, ppastells@eixampleclinic.es\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8a1d2",
   "metadata": {},
   "source": [
    "Avui veurem com realitzar l'etiquetatge Part-of-Speech (PoS) utilitzant NLTK. \n",
    "\n",
    "Farem servir diferents models segons l'n-grama triat i veurem l'importància de seleccionar un bon corpus d'entrenament.\n",
    "\n",
    "Presentarem també les mètriques i tècniques d'avaluació bàsiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c91cb-c4c3-4482-9a23-a284b11d6b2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Teoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60544bb-7554-4673-ab39-562988f16af1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Què és el Part-of-Speech?\n",
    "Una **Part-of-Speech (PoS)** o categoria gramatical és una etiqueta que s'assigna a cada paraula d'acord amb la seva funció dins d'una oració.\n",
    "\n",
    "*   **Conjunts d'etiquetes (Tagsets):**\n",
    "    *   **Simplificats:** Únicament marquen la categoria principal (Ex: \"nom\", \"verb\", \"adjectiu\").\n",
    "    *   **Complexos:** Contenen característiques gramaticals detallades (Ex: número, persona, forma verbal, gènere).\n",
    "*   **Evolució:**\n",
    "    *   Originalment, els conjunts d'etiquetes eren específics per a cada llengua.\n",
    "    *   Amb el desenvolupament de la lingüística computacional i el NLP, es van introduir els **conjunts d'etiquetes universals**. Podeu consultar-los a: [Universal Dependencies](https://universaldependencies.org/).\n",
    "\n",
    "## 2. El procés d'etiquetatge (PoS Tagging)\n",
    "El PoS Tagging és el procés automàtic d'assignar una etiqueta a cada paraula d'un text:\n",
    "*   *Jugant*: 'verb'\n",
    "*   *Cotxe*: 'nom'\n",
    "\n",
    "### El problema de l'ambigüitat\n",
    "\n",
    "Moltes paraules poden tenir diferents categories segons l'ús. Per exemple:\n",
    "\n",
    "- cura (NOM): remei o tractament.\n",
    "- cura (VERB): acció de guarir (del verb curar).\n",
    "\n",
    "Per desambiguar, necessitem observar el context:\n",
    "\n",
    "1. \"El metge ha trobat una cura per a la malaltia.\"  →  NOM\n",
    "2. \"Aquest medicament cura la infecció ràpidament.\"  →  VERB\n",
    "\n",
    "Un altre exemple molt comú:\n",
    "\n",
    "- baixa (NOM): document d'incapacitat laboral.\n",
    "- baixa (VERB): acció de descendir.\n",
    "- baixa (ADJECTIU): de poca altura o intensitat.\n",
    "\n",
    "Contextualització:\n",
    "\n",
    "1. \"L'infermer li ha tramitat la baixa.\"  →  NOM\n",
    "2. \"El pacient baixa amb l'ascensor.\"  →  VERB\n",
    "3. \"Té la pressió arterial molt baixa.\"  →  ADJECTIU\n",
    "\n",
    "**Com analitzem el context?**\n",
    "*   **Context Lineal:** Observem un número limitat de paraules abans i després (n-grames).\n",
    "*   **Per què no fem anàlisi sintàctic directament?** L'anàlisi sintàctic és molt més complex; generalment s'obtenen les etiquetes PoS com a pas previ necessari.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Etiquetatge basat en N-grames\n",
    "Aquests models prediuen l'etiqueta d'una paraula basant-se en la paraula actual i un context predefinit de paraules adjacents.\n",
    "\n",
    "### Elecció de l'N-grama:\n",
    "*   **Unigrames:** Prediu l'etiqueta utilitzant únicament la paraula actual. Si al corpus \"cura\" apareix el 90% de cops com a nom, sempre l'etiquetarà com a nom.\n",
    "*   **Bigrames:** Prediu l'etiqueta basant-se en la paraula actual i l'anterior (*\"la cura\"* $\\rightarrow$ NOM; *\"medicament cura\"* $\\rightarrow$ VERB).\n",
    "*   **Trigrames:** Utilitza 3 paraules consecutives per predir l'etiqueta.\n",
    "*   **N-grames de major ordre:** Ofereixen més context (més potència) però pateixen el problema de l'**escassetat de dades (data sparsity)**: és difícil trobar seqüències llargues exactes en el corpus d'entrenament.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Entrenament i Avaluació\n",
    "El PoS Tagging és un exemple d'**Aprenentatge Supervisat (Supervised Learning)**:\n",
    "\n",
    "1.  **Corpus Anotat:** Necessitem un conjunt de dades ja etiquetat per humans.\n",
    "2.  **Entrenament:** El model calcula les freqüències i probabilitats de cada paraula i cada seqüència (n-grama).\n",
    "3.  **Avaluació:** Provem el model amb dades que no ha vist mai per comprovar-ne la precisió (**Accuracy**). És vital separar el corpus en **Train** (entrenament) i **Test** (avaluació).\n",
    "\n",
    "### Possibles problemes:\n",
    "*   **Qualitat del corpus:** Si \"baixa\" només apareix com a verb al corpus d'entrenament, el model mai el marcarà com a nom.\n",
    "*   **Paraules desconegudes (Out-of-Vocabulary):** Si una paraula no apareix al training, el model no sabrà què fer. Solució: analitzar prefixos/sufixos (**AffixTagger**).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. La tècnica del Backoff\n",
    "El **Backoff** és una estratègia per compensar l'escassetat de dades combinant múltiples etiquetadors en cascada:\n",
    "\n",
    "1.  Intentem etiquetar amb el model més precís (ex: **Trigrames**).\n",
    "2.  Si el trigrama no coneix la combinació, \"baixem\" a un model de context menor (**Bigrames**).\n",
    "3.  Si aquest tampoc, baixem a **Unigrames**.\n",
    "4.  Com a última instància, usem un **DefaultTagger** (que etiqueta tot com a Substantiu, per exemple).\n",
    "\n",
    "---\n",
    "\n",
    "## Pràctica d'avui\n",
    "En aquesta sessió:\n",
    "*   Explorarem diferents etiquetadors de la llibreria **NLTK**.\n",
    "*   Comprovarem l'efectivitat del **Backoff**.\n",
    "*   Veurem com responen els models davant de vocabulari general vs. vocabulari mèdic/específic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098aa0af-bdab-4d14-b5a5-64fad1609b3f",
   "metadata": {},
   "source": [
    "# Codi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54495bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a6228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarreguem els paquets importants per la sessió d'avui\n",
    "nltk.download(\"brown\")\n",
    "nltk.download(\"universal_tagset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b049fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importem els recursos NLTK necessaris i la resta de llibreries:\n",
    "# Importar etiquetadores\n",
    "from nltk import (\n",
    "    AffixTagger,\n",
    "    BigramTagger,\n",
    "    ClassifierBasedPOSTagger,\n",
    "    ConfusionMatrix,\n",
    "    DefaultTagger,\n",
    "    TrigramTagger,\n",
    "    UnigramTagger,\n",
    "    bigrams,\n",
    "    trigrams,\n",
    ")\n",
    "\n",
    "# Importar el corpus brown\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a15eff",
   "metadata": {},
   "source": [
    "## Etiquetatge PoS a Python\n",
    "\n",
    "A continuació repassarem com podem accedir al contingut del corpus amb què treballarem. Tenim les frases etiquetades, paraula a paraula, amb les seves categories. Prèviament, s'han hagut de tokenitzar (recordem la sessió passada).\n",
    "\n",
    "Ens centrarem en els models 'taggers' basats en n-grames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785202d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenim una llista amb les categories del corpus brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenim la versió tokenitzada i etiquetada de la categoria 'news'\n",
    "brown_twords = brown.tagged_words(categories=\"news\")\n",
    "\n",
    "# Obtenim la mateixa versió que abans, però a més, segmentada per frases\n",
    "brown_tsents = brown.tagged_sents(categories=\"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenim les 5 primeres paraules etiquetades\n",
    "print(\"\\nLes primeres 5 paraules de la versió tokenitzada i etiquetada són:\")\n",
    "print(brown_twords[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cfc646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observem les dues primeres frases\n",
    "print(\"\\nLes primeres 2 frases de la versió amb frases segmentades són:\")\n",
    "print(brown_tsents[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenim el conjunt de totes les etiquetes que apareixen en el corpus brown\n",
    "brown_tags = set([tag for (token, tag) in brown_twords])\n",
    "print(\"\\nEl conjunt d'etiquetes en el corpus brown és:\")\n",
    "print(len(brown_tags), brown_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2230096-77cc-498f-87ae-1f7624930dd9",
   "metadata": {},
   "source": [
    "Veiem que n'hi ha un munt. El corpus __Brown__ està anotat amb molta precisió. Si volem comparar les etiquetes amb les d'Universal Dependencies, podem fer servir `tagset=\"universal\"`.\n",
    "\n",
    "### Incís\n",
    "\n",
    "Cada corpus pot tenir un seguit d'etiquetes diferents.\n",
    "- Les d'Universal Dependencies les podeu trobar a: https://universaldependencies.org/u/pos/index.html\n",
    "- Les etiquetes que fa servir NLTK (almenys per l'anglès) són les del Penn TreeBank https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "- La relació entre Penn i Universal Dependencies la podeu trobar a https://universaldependencies.org/tagset-conversion/en-penn-uposf.html\n",
    "- Les etiquetes del corpus Brown són https://varieng.helsinki.fi/CoRD/corpora/BROWN/tags.html, a més s'utilitzen sufixos per indicar el context, e.g., títol (-TL), i _+_ simbolitza formes contretes (I'm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ara obtenim i visualitzem totes les etiquetes existents en el set 'universal'\n",
    "brown_utwords = brown.tagged_words(categories=\"news\", tagset=\"universal\")\n",
    "universal_tags = set([tag for (token, tag) in brown_utwords])\n",
    "print(\"\\nEl conjunt d'etiquetes universals és:\")\n",
    "print(len(universal_tags), universal_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff72741-c197-441b-845a-3139de1b0ffe",
   "metadata": {},
   "source": [
    "### Tipus d'etiquetadors\n",
    "\n",
    "Coneixent ja com accedir al contingut etiquetat del corpus, entrenarem i avaluarem els diferents models d'etiquetatge:\n",
    "\n",
    "- **default** (etiquetatge per defecte)\n",
    "- **affix** (etiquetatge per prefixos/sufixos)\n",
    "- **unigram** (etiquetatge basat en un sol token)\n",
    "- **bigram** (etiquetatge basat en conjunts de dos tokens)\n",
    "- **trigram** (etiquetatge basat en conjunts de tres tokens)\n",
    "\n",
    "### Mètrica d'avaluació\n",
    "\n",
    "Per avaluar els models, farem servir la mètrica **Accuracy** (precisió), que es formula de la següent manera:\n",
    "\n",
    "\n",
    "$$\n",
    "    Accuracy = \\frac{\\# Prediccions Correctes}{\\# Prediccions} \n",
    "$$\n",
    "\n",
    "El valor d'accuracy oscil·larà del 0 al 1, sent 0 una detecció nul·la, i 1 una molt bona precisió del model. Tenir un valor prop del 0.5 voldrà dir que el model prediu quasi com llençant una moneda a cara o creu..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd33e53",
   "metadata": {},
   "source": [
    "## Entrenament i avaluació"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54d1d8-750b-41db-849f-47babe43b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAGSET = \"universal\"\n",
    "TAGSET = None  # per defecte, etiquetes completes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92460d4-f672-4ef4-abdc-902d7cb556c5",
   "metadata": {},
   "source": [
    "### Etiquetador per defecte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenim la versió segmentada i tokenitzada de 'news'\n",
    "brown_sents = brown.sents(categories=\"news\")\n",
    "# així com les frases etiquetades,\n",
    "brown_tsents = brown.tagged_sents(categories=\"news\", tagset=TAGSET)\n",
    "\n",
    "# Obtenim una llista de totes les etiquetes del corpus\n",
    "tags = [tag for (word, tag) in brown.tagged_words(categories=\"news\", tagset=TAGSET)]\n",
    "print(\"Hi ha un total de {} tags (mostres en el conjunt dataset)\\n\".format(len(tags)))\n",
    "\n",
    "# Desem l'etiqueta més freqüent del corpus\n",
    "most_frequent_tag = nltk.FreqDist(tags).max()\n",
    "print(\"l'etiqueta més freqüent és:\", most_frequent_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2b33a1-01d5-4657-939f-03da446d2dcf",
   "metadata": {},
   "source": [
    "Configurem un etiquetador per defecte.\n",
    "Assignarà la mateixa etiqueta per defecte a tots els tokens del corpus.\n",
    "El configurem perquè posi l'etiqueta més freqüent a tots els tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tagger = nltk.DefaultTagger(most_frequent_tag)\n",
    "\n",
    "my_sent = \"the quick brown fox jumped over the lazy dog\".split()\n",
    "print(\"Etiquetatge per defecte:\")\n",
    "print(default_tagger.tag(my_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf840b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluem l'etiquetador per defecte en el corpus:\n",
    "print(\n",
    "    \"La precisió de l'etiquetador per defecte en el corpus Brown es:\",\n",
    "    round(default_tagger.accuracy(brown_tsents), 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ddd6f-21c5-4dbb-b72c-e17ccad55e71",
   "metadata": {},
   "source": [
    "Per la resta d'etiquetadors, dividirem el corpus en 'train' i 'test':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ffe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tsents = brown.tagged_sents(categories=\"news\", tagset=TAGSET)\n",
    "\n",
    "test_corpus = brown_tsents[:800]\n",
    "train_corpus = brown_tsents[800:]\n",
    "\n",
    "print(test_corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3616a-6b6e-498b-9931-49ec102c6727",
   "metadata": {},
   "source": [
    "### AffixTagger\n",
    "\n",
    "És un etiquetador que es basa en prefixos i sufixos. S'entrena tenint en compte una longitud fixa de principi o final de paraula que definim prèviament.\n",
    "Variant el paràmetre `affix_length` canviem què es consiedera una affix. Un valor positiu serà un prefix, negatiu un sufix. Valor negatiu busca sufixos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrena el etiquetador affix\n",
    "affix_tagger = AffixTagger(train_corpus, affix_length=2)\n",
    "# prova a canviar l'affix_lenght a veure si canvia el resultat\n",
    "\n",
    "# Etiqueta el corpus\n",
    "affix_sents = affix_tagger.tag_sents(test_corpus)\n",
    "\n",
    "# Imprimim la primera frase i l'accuracy del model:\n",
    "print(\"\\nLa primera frase etiquetada amb l'affix tagger és:\")\n",
    "print(affix_sents[0])\n",
    "\n",
    "print(\"\\nL'accuracy de l'affix tagger és:\", round(affix_tagger.accuracy(test_corpus), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0795d2c-0f4f-45f8-a32e-d5d294c5f62e",
   "metadata": {},
   "source": [
    "#### Exemple amb paraules del món clínic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85d3ef-8b13-416b-b667-cb8e1ed79d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creem un corpus d'entrenament, dividit per \"famílies\" de sufixos\n",
    "# El format ha de ser una llista de llistes de tuples (simulant frases)\n",
    "train_medical = [\n",
    "    [\n",
    "        # Sufixos de malaltia: -itis (4 lletres) -> Substantiu\n",
    "        (\"gastritis\", \"NN\"),\n",
    "        (\"arthritis\", \"NN\"),\n",
    "        (\"hepatitis\", \"NN\"),\n",
    "        (\"nephritis\", \"NN\"),\n",
    "        (\"dermatitis\", \"NN\"),\n",
    "        # Sufixos d'especialitat: -logy / -logia (4 lletres) -> Substantiu\n",
    "        (\"cardiology\", \"NN\"),\n",
    "        (\"neurology\", \"NN\"),\n",
    "        (\"oncology\", \"NN\"),\n",
    "        (\"pathology\", \"NN\"),\n",
    "        (\"hematology\", \"NN\"),\n",
    "        # Sufixos d'adjectius: -tric (4 lletres) -> Adjectiu\n",
    "        (\"geriatric\", \"JJ\"),\n",
    "        (\"psychiatric\", \"JJ\"),\n",
    "        (\"pediatric\", \"JJ\"),\n",
    "        (\"obstetric\", \"JJ\"),\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Entrenem l'AffixTagger\n",
    "# Fem servir affix_length=-4 perquè molts sufixos mèdics tenen 4 lletres\n",
    "suffix_tagger = AffixTagger(train_medical, affix_length=-4)\n",
    "\n",
    "# Testejem amb paraules que NO estan a train_medical\n",
    "test_words = [\"bronchitis\", \"radiology\", \"pediatric\"]\n",
    "\n",
    "print(\"Resultats per sufixos (-4 lletres):\")\n",
    "for word in test_words:\n",
    "    tag = suffix_tagger.tag([word])\n",
    "    print(f\"{word} -> {tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3197d18-e556-4c30-beb3-379569119dcc",
   "metadata": {},
   "source": [
    "### N-gram taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenem amb el mateix corpus de 'train' un unigram tagger:\n",
    "unigram_tagger = UnigramTagger(train_corpus)\n",
    "\n",
    "# Etiquetem corpus per visualitzar resultat\n",
    "uni_sents = unigram_tagger.tag_sents(test_corpus)\n",
    "\n",
    "# Visualitzem\n",
    "print(\"\\nLa primera frase etiquetada amb l'unigram tagger és:\")\n",
    "print(uni_sents[0])\n",
    "\n",
    "# Mesurem precisió amb el corpus 'test'\n",
    "print(\"\\nL'accuracy de l'unigram tagger és:\", round(unigram_tagger.accuracy(test_corpus), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamient d'un bigram tagger\n",
    "bigram_tagger = BigramTagger(train_corpus)\n",
    "\n",
    "# Etiquetem\n",
    "bi_sents = bigram_tagger.tag_sents(test_corpus)\n",
    "\n",
    "# Visualitzem\n",
    "print(\"\\nPrimera frase etiquetada amb el model PoS tagger basat en bigrames és:\")\n",
    "print(bi_sents[0])\n",
    "\n",
    "# Avaluem\n",
    "print(\n",
    "    \"\\nLa precisió de l'etiquetador basat en bigrames en el corpus és:\",\n",
    "    round(bigram_tagger.accuracy(test_corpus), 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenament d'un trigram tagger:\n",
    "trigram_tagger = TrigramTagger(train_corpus)\n",
    "\n",
    "# Etiquetat\n",
    "tri_sents = trigram_tagger.tag_sents(test_corpus)\n",
    "\n",
    "# Visualització\n",
    "print(\"\\nPrimera frase etiquetada amb el model PoS tagger basat en trigrames és:\")\n",
    "print(tri_sents[0])\n",
    "\n",
    "# Avaluació\n",
    "print(\n",
    "    \"\\nLa precisió de l'etiquetador basat en trigrames en el corpus és:\",\n",
    "    round(trigram_tagger.accuracy(test_corpus), 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91009c4",
   "metadata": {},
   "source": [
    "#### Apliquem el model 'backoff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c80736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenament d'un bigram tagger amb backoff definit com un unigram tagger (l'anterior entrenat)\n",
    "bigram_tagger_backoff = BigramTagger(train_corpus, backoff=unigram_tagger)\n",
    "\n",
    "# Etiquetat per veure la diferència\n",
    "bi_sents_bo = bigram_tagger_backoff.tag_sents(test_corpus)\n",
    "\n",
    "# Visualitzem\n",
    "print(\"\\nLa primera frase etiquetada amb l'etiquetador basat en bigrames amb backoff és:\")\n",
    "print(bi_sents_bo[0])\n",
    "\n",
    "# Avaluació\n",
    "print(\n",
    "    \"\\nLa precisió de l'etiquetador basat en bigrames amb backoff en el corpus és:\",\n",
    "    round(bigram_tagger_backoff.accuracy(test_corpus), 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad4b27c-1c7c-47d7-9ad6-b01d4f45a258",
   "metadata": {},
   "source": [
    "### Tasca 1\n",
    "\n",
    "Entrena i avalua en el mateix corpus, en comptes de fer servir una partició de _test_ separada. Quin es el resultat?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1009a17-7754-4760-af27-e9a53d1a3cea",
   "metadata": {},
   "source": [
    "### Tasca 2\n",
    "\n",
    "Prova d'avaluar un etiquetador en un domini diferent a l'entrenat (cross-domain).\n",
    "\n",
    "Per exemple, entrena al corpus \"news\" i avalua al corpus \"science_fiction\", compara-ho amb entrenar i avaluar al mateix corpus \"science_fiction\".\n",
    "\n",
    "#### EXTRA\n",
    "\n",
    "Fes una taula (e.g., llista de llistes o CSV) on es mostrin totes les combinacions de diferents categories. \n",
    "\n",
    "Si ho fas amb totes les categories és possible que tardi bastant. Prova-ho amb 3 o 4 categories, però intenta fer el codi genèric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b6066-ab94-4a4a-8299-398ee8b32d2c",
   "metadata": {},
   "source": [
    "### Tasca 3\n",
    "\n",
    "Entreneu i avalueu els mateixos models tagger que hem vist però amb tot el corpus Brown (sense `categories=`) separat per 'train' i 'test'.\n",
    "\n",
    "Dividiu (aproximadament) 'train' 80% i 'test' 20% del total de dades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369aad5-9f2d-4e3e-acf7-4a6a79a0c033",
   "metadata": {},
   "source": [
    "### Tasca 4\n",
    "Crea una seqüència d'etiquetadors a mode de backoff:\n",
    "trigram -> bigram -> unigram -> affix -> default\n",
    "\n",
    "Utilitzeu tot el corpus brown i separeu en 'train' i 'test'.\n",
    "\n",
    "Avalua l'etiquetador resultant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e5f95-08bc-4d17-989e-4930e88428f1",
   "metadata": {},
   "source": [
    "### Tasca 5 - Importància del conjunt d'etiquetes\n",
    "Prova a refer algun dels exercicis anteriors amb les etiquetes \"universal\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
